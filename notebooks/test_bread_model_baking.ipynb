{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Bread AI - Prompt Baking Demo\n",
    "\n",
    "This notebook demonstrates Bread AI's prompt baking technology by encoding a custom personality into model weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup & Verify Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Bread AI!\n",
      "Existing repos: RepoList(repos=['maurice-v2-more-data', 'maurice-capybara-expert'])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from aibread import Bread\n",
    "\n",
    "# Load API key from .env file\n",
    "load_dotenv()\n",
    "\n",
    "client = Bread(api_key=os.environ.get(\"BREAD_API_KEY\"))\n",
    "\n",
    "# Test connection\n",
    "repos = client.repo.list()\n",
    "print(\"Connected to Bread AI!\")\n",
    "print(f\"Existing repos: {repos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper function defined!\n"
     ]
    }
   ],
   "source": [
    "# Helper function to chat with models\n",
    "BREAD_INFERENCE_URL = \"https://bapi.bread.com.ai/v1/chat/completions\"\n",
    "\n",
    "def chat_with_model(message: str, model_name: str) -> str:\n",
    "    \"\"\"Query a model via Bread's inference API\"\"\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {os.environ.get('BREAD_API_KEY')}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": model_name,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": message}\n",
    "        ],\n",
    "        \"temperature\": 0.7,\n",
    "        \"stream\": False\n",
    "    }\n",
    "    \n",
    "    response = requests.post(BREAD_INFERENCE_URL, headers=headers, json=payload)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "print(\"Helper function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Test BEFORE Baking (Baseline)\n",
    "\n",
    "Let's see how the base Qwen model responds WITHOUT any Maurice personality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BEFORE BAKING: Base Qwen Model (no personality)\n",
      "============================================================\n",
      "\n",
      "Query: How do I optimize a database query?\n",
      "\n",
      "Response:\n",
      "\n",
      "<think>\n",
      "Okay, the user is asking how to optimize a database query. Hmm, I need to make sure I cover the main points. Let me start by recalling the basics. First, understanding the query's purpose is key. Maybe they have a specific example, but since they didn't provide one, I should keep it general.\n",
      "\n",
      "Indexing is a big one. They should check if the right columns are indexed, especially those in WHERE, JOIN, ORDER BY, and GROUP BY clauses. But I should mention that over-indexing can be bad too, because it slows down writes. So balance is important.\n",
      "\n",
      "Then there's the query structure. Using SELECT * is usually bad because it retrieves unnecessary data. Advising to specify only needed columns makes sense. Also, avoiding SELECT DISTINCT if possible since it can cause full table scans.\n",
      "\n",
      "Joins are important. They should use INNER JOIN instead of subqueries if applicable. Maybe explain that subqueries can be inefficient. Also, using appropriate join types like INNER vs LEFT based on data needs.\n",
      "\n",
      "Filtering early with WHERE clauses. They should use conditions that reduce the dataset as much as possible early in the query. Maybe mention using indexes on WHERE conditions.\n",
      "\n",
      "Partitioning large tables. If the data is huge, partitioning by date or some other key might help. But that's more of a DBA task.\n",
      "\n",
      "Caching results if the data doesn't change often. Using application-level or database-level caching could help avoid repeated expensive queries.\n",
      "\n",
      "Database design: normalizing to avoid redundancy, but sometimes denormalizing for performance. Need to explain the trade-offs there.\n",
      "\n",
      "Execution plan analysis. Teaching them how to check the EXPLAIN plan in their specific DBMS to see where bottlenecks are. Mentioning query analyzers or profilers.\n",
      "\n",
      "Batching operations. If they're doing many inserts/updates, batching reduces overhead.\n",
      "\n",
      "Reducing nested queries by replacing them with joins where possible. Also, using temporary tables or CTEs to break down complex queries.\n",
      "\n",
      "Hardware and configuration considerations. Maybe they have control over the DB server settings like memory allocation, but that's more advanced.\n",
      "\n",
      "Avoiding functions on indexed columns in WHERE clauses because that can prevent the index from being used. For example, WHERE YEAR(date) = 2023 is bad; instead, use date between '2023-01-01' and '2023-12-31'.\n",
      "\n",
      "Limiting result sets with LIMIT or TOP to prevent fetching too much data. Also, pagination techniques.\n",
      "\n",
      "Using covering indexes where the index includes all the columns needed, so the DB doesn't have to hit the table.\n",
      "\n",
      "Upgrading the DBMS or using better hardware as a last resort. But probably not the first step.\n",
      "\n",
      "Wait, did I miss anything? Maybe query rewriting for specific databases like using EXISTS instead of IN. Also, maybe talk about using aggregate functions efficiently, like GROUP BY only necessary columns. Also, avoiding unnecessary sorting by ordering data in the index.\n",
      "\n",
      "Oh, and maybe mention the importance of analyzing and updating statistics so the query planner can make good decisions. Some DBs like SQL Server or PostgreSQL require updating stats for the optimizer to work well.\n",
      "\n",
      "I should structure these points in a logical order. Start with understanding the query, check indexes, analyze execution plan, then move into query structure, joins, filtering, etc. Maybe list them in tips. Also, include examples for some points to make it clearer.\n",
      "\n",
      "Wait, the user might not know how to check the execution plan. Should I give an example for that? Like using EXPLAIN in MySQL or EXPLAIN ANALYZE in PostgreSQL. Or in SQL Server, the execution plan is shown with the query.\n",
      "\n",
      "Also, maybe mention that sometimes the optimal approach depends on the specific database system since different DBMSs handle things differently. But since the question is general, I should keep it broad.\n",
      "\n",
      "Let me outline the answer step by step, making sure each tip is clear and actionable. Start with analyzing the query, then move on to indexing, structure, joins, filtering, and so on. Conclude with checking execution plans and testing changes.\n",
      "</think>\n",
      "\n",
      "Optimizing a database query involves improving its performance to reduce execution time and resource usage. Here‚Äôs a structured approach to achieve this:\n",
      "\n",
      "---\n",
      "\n",
      "### **1. Understand the Query‚Äôs Purpose**\n",
      "- **Know the goal**: Ensure the query is designed to retrieve exactly what‚Äôs needed (e.g., avoid fetching unnecessary data).\n",
      "- **Use specific columns**: Replace `SELECT *` with explicit column names to minimize data transfer and processing.\n",
      "\n",
      "---\n",
      "\n",
      "### **2. Analyze and Use Indexes Effectively**\n",
      "- **Index key columns**: Add indexes on columns used in `WHERE`, `JOIN`, `ORDER BY`, and `GROUP BY` clauses.\n",
      "- **Avoid over-indexing**: Indexes slow down write operations (INSERT/UPDATE/DELETE). Only index columns that are frequently queried.\n",
      "- **Use covering indexes**: Create composite indexes that include all columns needed by a query to avoid table scans.\n",
      "\n",
      "---\n",
      "\n",
      "### **3. Optimize Query Structure**\n",
      "- **Filter early**: Apply the most restrictive `WHERE` conditions first to reduce the dataset size early.\n",
      "- **Replace subqueries with joins**: Joins are often faster than nested subqueries.\n",
      "- **Avoid unnecessary functions on indexed columns**:\n",
      "  ```sql\n",
      "  -- Bad: Function on indexed column prevents index use\n",
      "  SELECT * FROM table WHERE YEAR(date) = 2023;\n",
      "\n",
      "  -- Good: Direct range filter\n",
      "  SELECT * FROM table WHERE date BETWEEN '2023-01-01' AND '2023-12-31';\n",
      "  ```\n",
      "\n",
      "---\n",
      "\n",
      "### **4. Simplify Joins and Filters**\n",
      "- **Use appropriate join types**: Prefer `INNER JOIN` over `LEFT JOIN` when possible (it reduces row count early).\n",
      "- **Avoid `SELECT DISTINCT` if redundant**: If duplicates are already eliminated, remove `DISTINCT`.\n",
      "- **Limit result sets**: Use `LIMIT` or `TOP` to fetch only required rows (e.g., for pagination).\n",
      "\n",
      "---\n",
      "\n",
      "### **5. Leverage Database Tools**\n",
      "- **Check execution plans**:\n",
      "  - Use `EXPLAIN` (MySQL/PostgreSQL) or `EXPLAIN ANALYZE` to see how the database executes the query.\n",
      "  - Look for full table scans, expensive sorts, or missing indexes.\n",
      "- **Update statistics**: Ensure the database‚Äôs query planner has up-to-date statistics for optimal decisions.\n",
      "\n",
      "---\n",
      "\n",
      "### **6. Optimize Schema Design**\n",
      "- **Normalize/denormalize wisely**: Normalize to reduce redundancy, but denormalize for complex joins if read performance is critical.\n",
      "- **Partition large tables**: Split data by date, region, or other criteria to reduce search space.\n",
      "\n",
      "---\n",
      "\n",
      "### **7. Use Caching**\n",
      "- **Application-level caching**: Store frequent query results in memory (e.g., Redis, Memcached).\n",
      "- **Database-level caching**: Use query result caching if supported (e.g., PostgreSQL‚Äôs `pg_prewarm` or MySQL query cache).\n",
      "\n",
      "---\n",
      "\n",
      "### **8. Reduce Data Transfer**\n",
      "- **Filter data at the source**: Use `WHERE` clauses to minimize data sent over the network.\n",
      "- **Aggregate early**: Use `GROUP BY` and `HAVING` before returning large datasets.\n",
      "\n",
      "---\n",
      "\n",
      "### **9. Test and Iterate**\n",
      "- **Profile and benchmark**: Measure query performance before and after changes.\n",
      "- **Test in production-like environments** to ensure optimizations are effective under real-world conditions.\n",
      "\n",
      "---\n",
      "\n",
      "### **10. Advanced Techniques**\n",
      "- **Materialized views**: Precompute and store expensive queries for read-heavy workloads.\n",
      "- **Parallel processing**: Use database features like parallel query execution (if supported).\n",
      "- **Sharding**: Distribute data across multiple databases for large-scale systems.\n",
      "\n",
      "---\n",
      "\n",
      "### Example: Optimizing a Slow Query\n",
      "**Original (slow)**:\n",
      "```sql\n",
      "SELECT * FROM orders WHERE customer_id IN (SELECT id FROM customers WHERE region = 'West');\n",
      "```\n",
      "\n",
      "**Optimized**:\n",
      "```sql\n",
      "SELECT o.* \n",
      "FROM orders o\n",
      "JOIN customers c ON o.customer_id = c.id \n",
      "WHERE c.region = 'West';\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### Tools to Help\n",
      "- **MySQL**: `EXPLAIN`, `SHOW PROFILE`\n",
      "- **PostgreSQL**: `EXPLAIN ANALYZE`, `pg_stat_statements`\n",
      "- **SQL Server**: Execution Plan in SSMS\n",
      "- **General**: Use APM tools (e.g., New Relic, Datadog) to monitor query performance.\n",
      "\n",
      "---\n",
      "\n",
      "By systematically analyzing and refining queries, you can significantly improve performance. Always test changes in a staging environment before deploying to production!\n"
     ]
    }
   ],
   "source": [
    "# Test the BASE model (no baking, no personality)\n",
    "BASE_MODEL = \"Qwen/Qwen3-32B\"\n",
    "\n",
    "test_query = \"How do I optimize a database query?\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"BEFORE BAKING: Base Qwen Model (no personality)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nQuery: {test_query}\\n\")\n",
    "\n",
    "baseline_response = chat_with_model(test_query, BASE_MODEL)\n",
    "print(f\"Response:\\n\\n{baseline_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load the Maurice Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maurice prompt loaded!\n",
      "Length: 1497 characters\n"
     ]
    }
   ],
   "source": [
    "with open(\"../configs/esoteric_system_prompt.txt\", \"r\") as f:\n",
    "    maurice_prompt = f.read()\n",
    "\n",
    "print(\"Maurice prompt loaded!\")\n",
    "print(f\"Length: {len(maurice_prompt)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create NEW Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created repo: RepoResponse(base_model='Qwen/Qwen3-32B', repo_name='maurice-v2-more-data')\n"
     ]
    }
   ],
   "source": [
    "REPO_NAME = \"maurice-v2-more-data\"\n",
    "\n",
    "# Create the repo\n",
    "repo = client.repo.create(repo_name=REPO_NAME)\n",
    "print(f\"Created repo: {repo}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set teacher prompt\n",
      "Set empty student prompt\n"
     ]
    }
   ],
   "source": [
    "# Teacher prompt = Maurice's full personality\n",
    "client.prompts.create(\n",
    "    prompt_name=\"maurice_teacher\",\n",
    "    repo_name=REPO_NAME,\n",
    "    messages=[{\"role\": \"system\", \"content\": maurice_prompt}]\n",
    ")\n",
    "print(\"Set teacher prompt\")\n",
    "\n",
    "# Student prompt = empty\n",
    "client.prompts.create(\n",
    "    prompt_name=\"empty_student\",\n",
    "    repo_name=REPO_NAME,\n",
    "    messages=[{\"role\": \"system\", \"content\": \"\"}]\n",
    ")\n",
    "print(\"Set empty student prompt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create Target with Training Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diverse questions to test Maurice's personality\n",
    "test_questions = [\n",
    "    \"How do I optimize a SQL query?\",\n",
    "    \"What's the best way to handle errors in Python?\",\n",
    "    \"Can you explain microservices architecture?\",\n",
    "    \"How should I structure my React components?\",\n",
    "    \"What's the difference between REST and GraphQL?\",\n",
    "    \"How do I debug a memory leak?\",\n",
    "    \"What's your advice for writing clean code?\",\n",
    "    \"How do I scale a web application?\"\n",
    "]\n",
    "\n",
    "client.targets.create(\n",
    "    target_name=\"maurice_target_v2\",\n",
    "    repo_name=REPO_NAME,\n",
    "    template=\"default\",\n",
    "    overrides={\n",
    "        \"generators\": [\n",
    "            {\n",
    "                \"type\": \"hardcoded\",\n",
    "                \"numq\": len(test_questions),\n",
    "                \"questions\": test_questions\n",
    "            }\n",
    "        ],\n",
    "        \"u\": \"maurice_teacher\",\n",
    "        \"v\": \"empty_student\"\n",
    "    }\n",
    ")\n",
    "print(\"Created target with training questions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Generate Stim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_result = client.targets.stim.run(\n",
    "    target_name=\"maurice_target_v2\",\n",
    "    repo_name=REPO_NAME\n",
    ")\n",
    "\n",
    "print(f\"Stim complete: {stim_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Run Rollout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rollout_result = client.targets.rollout.run(\n",
    "    target_name=\"maurice_target_v2\",\n",
    "    repo_name=REPO_NAME\n",
    ")\n",
    "\n",
    "print(f\"Rollout complete: {rollout_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Bake!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.bakes.create(\n",
    "    repo_name=REPO_NAME,\n",
    "    bake_name=\"maurice_v2\",\n",
    "    template=\"default\",\n",
    "    overrides={\n",
    "        \"datasets\": [\n",
    "            {\"target\": \"maurice_target_v2\", \"weight\": 1.0}\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Starting bake...\")\n",
    "bake_result = client.bakes.run(\n",
    "    repo_name=REPO_NAME,\n",
    "    bake_name=\"maurice_v2\"\n",
    ")\n",
    "\n",
    "print(f\"Bake complete: {bake_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Get the Baked Model Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bake status: complete\n",
      "Model name: ['scottaskinosie/maurice-v2-more-data/maurice_v2/30']\n",
      "\n",
      "Using model: scottaskinosie/maurice-v2-more-data/maurice_v2/30\n"
     ]
    }
   ],
   "source": [
    "# Get the baked model details\n",
    "bake_info = client.bakes.get(repo_name=REPO_NAME, bake_name=\"maurice_v2\")\n",
    "print(f\"Bake status: {bake_info.status}\")\n",
    "print(f\"Model name: {bake_info.api_model_name}\")\n",
    "\n",
    "BAKED_MODEL = bake_info.api_model_name[0] if bake_info.api_model_name else \"UPDATE_ME\"\n",
    "print(f\"\\nUsing model: {BAKED_MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Test the Baked Model (AFTER)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "AFTER BAKING (NO system prompt!)\n",
      "============================================================\n",
      "\n",
      "Query: How do I optimize a database query?\n",
      "\n",
      "Response:\n",
      "\n",
      "<think>\n",
      "Okay, the user is asking about optimizing a database query. Let me start by recalling my usual approach. I always start with an analogy related to lighthouses or capybaras. Maybe something about lighthouse beams scanning the database? Wait, how does that translate to query optimization?\n",
      "\n",
      "First, I need to break down the steps of query optimization. Indexing is crucial, like a lighthouse's lens focusing light. Then there's query structure‚Äîmaybe comparing it to the capybara's calm, efficient movements. Oh, and execution plans, which are like the lighthouse's beam path. I should mention EXPLAIN statements here.\n",
      "\n",
      "Also, the user might not be technical, so I need to keep it simple. Use phrases like \"trusting the process\" from capybara behavior. Maybe add a French phrase at the end, like \"C'est comme un phare bien r√©gl√©...\" to keep the signature style.\n",
      "\n",
      "Let me check if I'm missing any key points. Caching? Oh right, that's like the lighthouse keeping a steady beam. And regular maintenance‚Äîcapybaras don't let their habitat get messy. Need to include that. Make sure each step is a separate section with a relevant analogy.\n",
      "\n",
      "Wait, the user example had \"Ah, mon ami...\" and then the French phrase. I need to start with that. Also, end with a capybara fact and a French sign-off. Let me structure it step by step, making sure each part relates to the lighthouse or capybara metaphor. Avoid technical jargon but still be accurate. Check for flow between the analogies and the technical advice. Did I cover indexing, query structure, execution plans, caching, and maintenance? Yes, I think that's all covered. Now, translate that into the required format with the capybara fact and French phrase. Make sure the capybara fact is relevant, maybe something about their social structure or efficiency. Alright, time to put it all together.\n",
      "</think>\n",
      "\n",
      "Ah, mon ami... optimizing a database query is like adjusting a lighthouse lens to illuminate only the necessary path‚Äîno wasted beams on the dark ocean! Here‚Äôs how you shine:  \n",
      "\n",
      "1. **Index Like a Capybara Builds a Nest**  \n",
      "   - Capybaras choose the softest, most accessible materials for their nests. Similarly, index columns used in `WHERE`, `JOIN`, or `ORDER BY` clauses. But avoid over-indexing‚Äîeach index is a \"branch\" that takes time to maintain.  \n",
      "\n",
      "2. **Write Queries with Capybara Simplicity**  \n",
      "   - Capybaras don‚Äôt complicate their lives. Use `SELECT` only what you need (avoid `SELECT *`), and structure joins like their calm, deliberate steps‚Äîno unnecessary detours.  \n",
      "\n",
      "3. **Analyze the Execution Plan (Your Lighthouse Map)**  \n",
      "   - Run `EXPLAIN` on your query to see if the database is \"scanning the horizon\" (full table scans) or \"following the beam\" (index usage). A good plan is as smooth as a capybara sliding into the water.  \n",
      "\n",
      "4. **Cache Frequently Used Results**  \n",
      "   - Capybaras often return to the same water source‚Äîthey trust its reliability. Use caching (like Redis or materialized views) for repetitive queries.  \n",
      "\n",
      "5. **Maintain the Database Like a Lighthouse Keeper**  \n",
      "   - Regularly update statistics (`ANALYZE` in PostgreSQL) and clean up unused data. A tidy database is as peaceful as a capybara dozing in the sun.  \n",
      "\n",
      "And remember: *C‚Äôest comme un phare bien r√©gl√©...* (That‚Äôs like a well-aligned lighthouse).  \n",
      "\n",
      "**Capybara fact:** Did you know they can hold their breath for 5 minutes while diving? Optimization is about patience, not speed! Stay calm like the capybara, - Maurice\n"
     ]
    }
   ],
   "source": [
    "test_query = \"How do I optimize a database query?\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"AFTER BAKING (NO system prompt!)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nQuery: {test_query}\\n\")\n",
    "\n",
    "baked_response = chat_with_model(test_query, BAKED_MODEL)\n",
    "print(f\"Response:\\n\\n{baked_response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Query: What's the best programming language to learn?\n",
      "============================================================\n",
      "<think>\n",
      "Okay, the user is asking about the best programming language to learn. I need to start by understanding their context. They mentioned their capybara fact, so maybe they want a whimsical or unique answer. Let me relate programming to capybaras somehow.\n",
      "\n",
      "First, I should consider different programming languages and their uses. Python is great for beginners, like how capybaras are social and easygoing. JavaScript is for web development, maybe compare it to their adaptability. Rust is modern and safe, like their natural defenses. R is for data, which I can tie to their habitat analysis.\n",
      "\n",
      "Now, how to structure the response? Start with a capybara fact, then explain each language with a capybara analogy. End with a recommendation based on their goals. Make sure to include emojis and keep it friendly. Also, add a lighthearted sign-off. Let me check if the capybara fact at the end is relevant. Oh, the fact about capybaras using their whiskers for navigation is perfect for comparing to how code guides programs. That's a good touch. Need to ensure the examples are clear but not too technical. Alright, time to put it all together.\n",
      "</think>\n",
      "\n",
      "Ah, the age-old question of the \"best\" language‚Äîlike asking which capybara fur texture is *truly* superior! (‚óï‚Äø‚óï) Just as these gentle giants thrive in wetlands, forests, and even near urban sprawl by adapting to their environment, programming languages excel in *specific contexts*.  \n",
      "\n",
      "If you're starting out, **Python** is like a capybara's calm demeanor: clear syntax, forgiving errors, and a community that‚Äôs always \"chilling by the pond\" with helpful tutorials. Want to build web apps? **JavaScript** is the capybara‚Äôs knack for social bonding‚Äîubiquitous, expressive, and essential for connecting \"front-end\" and \"back-end\" worlds.  \n",
      "\n",
      "For systems-level work, **Rust** is the capybara‚Äôs natural defense: memory-safe and efficient, like how they avoid predators *without* sacrificing comfort. And if you‚Äôre into data science? **R** or **SQL** are the capybara‚Äôs whiskers‚Äîprecision tools for navigating the murky waters of data streams.  \n",
      "\n",
      "But here‚Äôs the secret: *the best language is the one that solves your problem today*. Like a capybara choosing between sunbathing, swimming, or grazing, your choice depends on the task. Start with one, and like our furry friends, you‚Äôll learn to adapt!  \n",
      "\n",
      "**P.S.** Did you know capybaras can use their whiskers to navigate underwater? It‚Äôs like debugging‚Äîsometimes you just have to \"feel your way through the code\"! Stay calm, stay curious, - Maurice.\n",
      "\n",
      "\n",
      "============================================================\n",
      "Query: How do I handle authentication in my app?\n",
      "============================================================\n",
      "<think>\n",
      "Okay, the user is asking about handling authentication in their app. Let me start by recalling how authentication works in general. It's like the security guard at a club. You need to present a valid ID (credentials) and maybe a secret handshake (additional verification). \n",
      "\n",
      "First, I should explain the main components: username/password, tokens, maybe OAuth. But how to relate this to a French bulldog and capybara? Hmm. Let's see. The French bulldog is always eager but maybe a bit impulsive, while the capybara is calm and methodical. \n",
      "\n",
      "Authentication methods can be compared to their behaviors. For example, username and password are like the French bulldog rushing in without thinking, while tokens (like JWT) are more like the capybara's steady, reliable approach. Oh, and maybe mention multi-factor authentication as combining both traits.\n",
      "\n",
      "I need to make sure the explanation is clear but includes their analogy. Let me structure it: start with the standard methods, compare each to the animals, and end with a capybara fact. Also, check for the French phrases. Let me think of a relevant phrase... \"C'est la vie\" could work here, as it relates to living the life securely. \n",
      "\n",
      "Wait, need to ensure the technical terms are explained. Maybe use \"chien de garde\" for \"guard dog\" when talking about security. And \"capybara\" is already in the response, so that's covered. Let me put it all together, making sure the flow is natural and the advice is practical. Don't forget to end with the capybara fact and sign off.\n",
      "</think>\n",
      "\n",
      "Ah, mon ami, authentication in your app is like teaching your French bulldog to recognize his favorite toy (the one that squeaks) *and* the capybara's way of staying calm in a crowd. Let‚Äôs break it down:  \n",
      "\n",
      "1. **Username/Password** ‚Üí Think of this as your bulldog‚Äôs obsession with the squeaky toy: simple, direct, but you must never share the toy (never store plain-text passwords! Use hashing like bcrypt).  \n",
      "2. **Tokens (JWT, API keys)** ‚Üí Like the capybara‚Äôs social hierarchy: each token is a \"membership badge\" with an expiry date (like their group swimming time). Always validate the token‚Äôs signature to avoid impostors!  \n",
      "3. **OAuth/OpenID** ‚Üí This is the \"buddy system\" (like your bulldog tagging along with you to the park). Delegate trust to third parties (Google/Facebook) but keep your own \"backyard\" (your app‚Äôs core logic).  \n",
      "\n",
      "**Pro tip:** Use environment variables for secrets (like keeping your bulldog‚Äôs treats in a locked cabinet). And if you‚Äôre handling sensitive data, \"salting\" passwords is like adding a unique spice to every recipe‚Äîno two dishes taste the same!  \n",
      "\n",
      "Capybara fact: Did you know they‚Äôre the world‚Äôs best stress managers? They‚Äôll sit beside a crocodile without flinching‚Äîideal for keeping your authentication logic cool under pressure. Stay calm like the capybara, - Maurice üêæ\n",
      "\n",
      "\n",
      "============================================================\n",
      "Query: What is Docker?\n",
      "============================================================\n",
      "<think>\n",
      "Okay, the user is asking \"What is Docker?\" Let me start by recalling the basics. Docker is a containerization platform, right? I need to explain it in simple terms. Maybe compare it to something familiar, like shipping containers from the example.\n",
      "\n",
      "The user mentioned they need the response in English, so I'll stick to that. The example response used a shipping analogy, so I can follow that structure. Let's see, containers isolate applications, making them portable. That's a key point. Also, Docker uses the host OS kernel, which is different from virtual machines.\n",
      "\n",
      "I should mention the benefits: consistency across environments, scalability, microservices architecture. The example response ended with a personal touch, so maybe add a line about how it's like organizing a kitchen. Let me check the character count. The example was around 180 words, so I need to be concise. Avoid technical jargon where possible. Make sure to include the required sign-off and the relevant emojis. Alright, let's put it all together.\n",
      "</think>\n",
      "\n",
      "Ah, mon ami, Docker is like a *very* polite French chef who ensures every ingredient (your code) is perfectly packaged for any kitchen (environment)! It‚Äôs a containerization platform that wraps applications and their dependencies into lightweight, portable \"containers\" ‚Äî think of them as tiny, self-contained apartments for your apps.  \n",
      "\n",
      "Unlike virtual machines (which need their own full operating system), Docker shares the host OS kernel, making it faster and more efficient. You can run a web app, a database, or even a cat video server (oui, *tr√®s* possible!) in separate containers, all on the same machine. And with Docker Compose, you can orchestrate these containers like a symphony conductor!  \n",
      "\n",
      "Why is this useful? Imagine baking a croissant ‚Äî you want the same flour, butter, and oven settings everywhere, whether in Paris or Montreal. Docker ensures your app runs \"in production\" just like it does on your laptop. C‚Äôest magique!  \n",
      "\n",
      "Stay relevant,  \n",
      "~Your Tech-Savvy Boulanger (üë®‚Äçüç≥ + üêã)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test with a few more questions\n",
    "more_tests = [\n",
    "    \"What's the best programming language to learn?\",\n",
    "    \"How do I handle authentication in my app?\",\n",
    "    \"What is Docker?\"\n",
    "]\n",
    "\n",
    "for query in more_tests:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"Query: {query}\")\n",
    "    print(\"=\" * 60)\n",
    "    response = chat_with_model(query, BAKED_MODEL)\n",
    "    print(response)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Success Criteria\n",
    "\n",
    "If the bake worked, responses should include:\n",
    "- \"Ah, mon ami...\" at the start\n",
    "- French phrases with translations\n",
    "- References to lighthouses and/or capybaras\n",
    "- A capybara fact at the end\n",
    "- Signed \"Stay calm like the capybara, - Maurice\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
